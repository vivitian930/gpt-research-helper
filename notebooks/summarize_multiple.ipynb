{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import arxiv\n",
    "import ast\n",
    "import concurrent\n",
    "from csv import writer\n",
    "from IPython.display import display, Markdown, Latex\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "import requests\n",
    "from scipy import spatial\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "from termcolor import colored\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\") \n",
    "openai.api_type = 'azure'\n",
    "openai.api_version = '2023-07-01-preview'\n",
    "\n",
    "GPT_MODEL = \"gpt-35-16k\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory './data/papers' already exists.\n"
     ]
    }
   ],
   "source": [
    "directory = './data/papers'\n",
    "\n",
    "# Check if the directory already exists\n",
    "if not os.path.exists(directory):\n",
    "    # If the directory doesn't exist, create it and any necessary intermediate directories\n",
    "    os.makedirs(directory)\n",
    "    print(f\"Directory '{directory}' created successfully.\")\n",
    "else:\n",
    "    # If the directory already exists, print a message indicating it\n",
    "    print(f\"Directory '{directory}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a directory to store downloaded papers\n",
    "data_dir = os.path.join(os.curdir, \"data\", \"papers\")\n",
    "paper_dir_filepath = \"./data/arxiv_library.csv\"\n",
    "\n",
    "# Generate a blank dataframe where we can store downloaded files\n",
    "df = pd.DataFrame(list())\n",
    "df.to_csv(paper_dir_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
    "def embedding_request(text):\n",
    "    response = openai.Embedding.create(input=text, engine=EMBEDDING_MODEL)\n",
    "    return response\n",
    "\n",
    "\n",
    "def get_articles(query, library=paper_dir_filepath, top_k=5):\n",
    "    \"\"\"This function gets the top_k articles based on a user's query, sorted by relevance.\n",
    "    It also downloads the files and stores them in arxiv_library.csv to be retrieved by the read_article_and_summarize.\n",
    "    \"\"\"\n",
    "    search = arxiv.Search(\n",
    "        query=query, max_results=top_k, sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "    result_list = []\n",
    "    for result in search.results():\n",
    "        result_dict = {}\n",
    "        result_dict.update({\"title\": result.title})\n",
    "        result_dict.update({\"summary\": result.summary})\n",
    "\n",
    "        # Taking the first url provided\n",
    "        result_dict.update({\"article_url\": [x.href for x in result.links][0]})\n",
    "        result_dict.update({\"pdf_url\": [x.href for x in result.links][1]})\n",
    "        result_list.append(result_dict)\n",
    "\n",
    "        # Store references in library file\n",
    "        response = embedding_request(text=result.title)\n",
    "        file_reference = [\n",
    "            result.title,\n",
    "            result.download_pdf(data_dir),\n",
    "            response[\"data\"][0][\"embedding\"],\n",
    "        ]\n",
    "\n",
    "        # Write to file\n",
    "        with open(library, \"a\") as f_object:\n",
    "            writer_object = writer(f_object)\n",
    "            writer_object.writerow(file_reference)\n",
    "            f_object.close()\n",
    "    return result_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Beyond Generating Code: Evaluating GPT on a Data Visualization Course',\n",
       " 'summary': \"This paper presents an empirical evaluation of the performance of the\\nGenerative Pre-trained Transformer (GPT) model in Harvard's CS171 data\\nvisualization course. While previous studies have focused on GPT's ability to\\ngenerate code for visualizations, this study goes beyond code generation to\\nevaluate GPT's abilities in various visualization tasks, such as data\\ninterpretation, visualization design, visual data exploration, and insight\\ncommunication. The evaluation utilized GPT-3.5 and GPT-4 to complete\\nassignments of CS171, and included a quantitative assessment based on the\\nestablished course rubrics, a qualitative analysis informed by the feedback of\\nthree experienced graders, and an exploratory study of GPT's capabilities in\\ncompleting border visualization tasks. Findings show that GPT-4 scored 80% on\\nquizzes and homework, and TFs could distinguish between GPT- and\\nhuman-generated homework with 70% accuracy. The study also demonstrates GPT's\\npotential in completing various visualization tasks, such as data cleanup,\\ninteraction with visualizations, and insight communication. The paper concludes\\nby discussing the strengths and limitations of GPT in data visualization,\\npotential avenues for incorporating GPT in broader visualization tasks, and the\\nneed to redesign visualization education.\",\n",
       " 'article_url': 'http://arxiv.org/abs/2306.02914v1',\n",
       " 'pdf_url': 'http://arxiv.org/pdf/2306.02914v1'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that the search is working\n",
    "result_output = get_articles(\"GPT Transformer Orignal Papers\")\n",
    "result_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\\'title\\': \\'Beyond Generating Code: Evaluating GPT on a Data Visualization Course\\', \\'summary\\': \"This paper presents an empirical evaluation of the performance of the\\\\nGenerative Pre-trained Transformer (GPT) model in Harvard\\'s CS171 data\\\\nvisualization course. While previous studies have focused on GPT\\'s ability to\\\\ngenerate code for visualizations, this study goes beyond code generation to\\\\nevaluate GPT\\'s abilities in various visualization tasks, such as data\\\\ninterpretation, visualization design, visual data exploration, and insight\\\\ncommunication. The evaluation utilized GPT-3.5 and GPT-4 to complete\\\\nassignments of CS171, and included a quantitative assessment based on the\\\\nestablished course rubrics, a qualitative analysis informed by the feedback of\\\\nthree experienced graders, and an exploratory study of GPT\\'s capabilities in\\\\ncompleting border visualization tasks. Findings show that GPT-4 scored 80% on\\\\nquizzes and homework, and TFs could distinguish between GPT- and\\\\nhuman-generated homework with 70% accuracy. The study also demonstrates GPT\\'s\\\\npotential in completing various visualization tasks, such as data cleanup,\\\\ninteraction with visualizations, and insight communication. The paper concludes\\\\nby discussing the strengths and limitations of GPT in data visualization,\\\\npotential avenues for incorporating GPT in broader visualization tasks, and the\\\\nneed to redesign visualization education.\", \\'article_url\\': \\'http://arxiv.org/abs/2306.02914v1\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2306.02914v1\\'}, {\\'title\\': \\'GPT Agents in Game Theory Experiments\\', \\'summary\\': \"This paper explores the potential of using Generative Pre-trained Transformer\\\\n(GPT)-based agents as participants in strategic game experiments. Specifically,\\\\nI focus on the finitely repeated ultimatum and prisoner\\'s dilemma games, two\\\\nwell-studied games in economics. I develop prompts to enable GPT agents to\\\\nunderstand the game rules and play the games. The results indicate that, given\\\\nwell-crafted prompts, GPT can generate realistic outcomes and exhibit behavior\\\\nconsistent with human behavior in certain important aspects, such as positive\\\\nrelationship between acceptance rates and offered amounts in the ultimatum game\\\\nand positive cooperation rates in the prisoner\\'s dilemma game. Some differences\\\\nbetween the behavior of GPT and humans are observed in aspects like the\\\\nevolution of choices over rounds. I also study two treatments in which the GPT\\\\nagents are prompted to either have social preferences or not. The treatment\\\\neffects are evident in both games. This preliminary exploration indicates that\\\\nGPT agents can exhibit realistic performance in simple strategic games and\\\\nshows the potential of using GPT as a valuable tool in social science research.\", \\'article_url\\': \\'http://arxiv.org/abs/2305.05516v1\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2305.05516v1\\'}, {\\'title\\': \\'How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation\\', \\'summary\\': \\'Generative Pre-trained Transformer (GPT) models have shown remarkable\\\\ncapabilities for natural language generation, but their performance for machine\\\\ntranslation has not been thoroughly investigated. In this paper, we present a\\\\ncomprehensive evaluation of GPT models for machine translation, covering\\\\nvarious aspects such as quality of different GPT models in comparison with\\\\nstate-of-the-art research and commercial systems, effect of prompting\\\\nstrategies, robustness towards domain shifts and document-level translation. We\\\\nexperiment with eighteen different translation directions involving high and\\\\nlow resource languages, as well as non English-centric translations, and\\\\nevaluate the performance of three GPT models: ChatGPT, GPT3.5\\\\n(text-davinci-003), and text-davinci-002. Our results show that GPT models\\\\nachieve very competitive translation quality for high resource languages, while\\\\nhaving limited capabilities for low resource languages. We also show that\\\\nhybrid approaches, which combine GPT models with other translation systems, can\\\\nfurther enhance the translation quality. We perform comprehensive analysis and\\\\nhuman evaluation to further understand the characteristics of GPT translations.\\\\nWe hope that our paper provides valuable insights for researchers and\\\\npractitioners in the field and helps to better understand the potential and\\\\nlimitations of GPT models for translation.\\', \\'article_url\\': \\'http://arxiv.org/abs/2302.09210v1\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2302.09210v1\\'}, {\\'title\\': \\'Event Stream GPT: A Data Pre-processing and Modeling Library for Generative, Pre-trained Transformers over Continuous-time Sequences of Complex Events\\', \\'summary\\': \\'Generative, pre-trained transformers (GPTs, a.k.a. \"Foundation Models\") have\\\\nreshaped natural language processing (NLP) through their versatility in diverse\\\\ndownstream tasks. However, their potential extends far beyond NLP. This paper\\\\nprovides a software utility to help realize this potential, extending the\\\\napplicability of GPTs to continuous-time sequences of complex events with\\\\ninternal dependencies, such as medical record datasets. Despite their\\\\npotential, the adoption of foundation models in these domains has been hampered\\\\nby the lack of suitable tools for model construction and evaluation. To bridge\\\\nthis gap, we introduce Event Stream GPT (ESGPT), an open-source library\\\\ndesigned to streamline the end-to-end process for building GPTs for\\\\ncontinuous-time event sequences. ESGPT allows users to (1) build flexible,\\\\nfoundation-model scale input datasets by specifying only a minimal\\\\nconfiguration file, (2) leverage a Hugging Face compatible modeling API for\\\\nGPTs over this modality that incorporates intra-event causal dependency\\\\nstructures and autoregressive generation capabilities, and (3) evaluate models\\\\nvia standardized processes that can assess few and even zero-shot performance\\\\nof pre-trained models on user-specified fine-tuning tasks.\\', \\'article_url\\': \\'http://arxiv.org/abs/2306.11547v2\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2306.11547v2\\'}, {\\'title\\': \\'Adapting GPT, GPT-2 and BERT Language Models for Speech Recognition\\', \\'summary\\': \\'Language models (LMs) pre-trained on massive amounts of text, in particular\\\\nbidirectional encoder representations from Transformers (BERT), generative\\\\npre-training (GPT), and GPT-2, have become a key technology for many natural\\\\nlanguage processing tasks. In this paper, we present results using fine-tuned\\\\nGPT, GPT-2, and their combination for automatic speech recognition (ASR).\\\\nUnlike unidirectional LM GPT and GPT-2, BERT is bidirectional whose direct\\\\nproduct of the output probabilities is no longer a valid language prior\\\\nprobability. A conversion method is proposed to compute the correct language\\\\nprior probability based on bidirectional LM outputs in a mathematically exact\\\\nway. Experimental results on the widely used AMI and Switchboard ASR tasks\\\\nshowed that the combination of the fine-tuned GPT and GPT-2 outperformed the\\\\ncombination of three neural LMs with different architectures trained from\\\\nscratch on the in-domain text by up to a 12% relative word error rate reduction\\\\n(WERR). Furthermore, on the AMI corpus, the proposed conversion for language\\\\nprior probabilities enables BERT to obtain an extra 3% relative WERR, and the\\\\ncombination of BERT, GPT and GPT-2 results in further improvements.\\', \\'article_url\\': \\'http://arxiv.org/abs/2108.07789v2\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2108.07789v2\\'}]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(result_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings_ranked_by_relatedness(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
    "    top_n: int = 100,\n",
    ") -> list[str]:\n",
    "    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n",
    "    query_embedding_response = embedding_request(query)\n",
    "    query_embedding = query_embedding_response[\"data\"][0][\"embedding\"]\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"filepath\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "    return strings[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(filepath):\n",
    "    \"\"\"Takes a filepath to a PDF and returns a string of the PDF's contents\"\"\"\n",
    "    # creating a pdf reader object\n",
    "    reader = PdfReader(filepath)\n",
    "    pdf_text = \"\"\n",
    "    page_number = 0\n",
    "    for page in reader.pages:\n",
    "        page_number += 1\n",
    "        pdf_text += page.extract_text() + f\"\\nPage Number: {page_number}\"\n",
    "    return pdf_text\n",
    "\n",
    "\n",
    "# Split a text into smaller chunks of size n, preferably ending at the end of a sentence\n",
    "def create_chunks(text, n, tokenizer):\n",
    "    \"\"\"Returns successive n-sized chunks from provided text.\"\"\"\n",
    "    tokens = tokenizer.encode(text)\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # Find the nearest end of sentence within a range of 0.5 * n and 1.5 * n tokens\n",
    "        j = min(i + int(1.5 * n), len(tokens))\n",
    "        while j > i + int(0.5 * n):\n",
    "            # Decode the tokens and check for full stop or newline\n",
    "            chunk = tokenizer.decode(tokens[i:j])\n",
    "            if chunk.endswith(\".\") or chunk.endswith(\"\\n\"):\n",
    "                break\n",
    "            j -= 1\n",
    "        # If no end of sentence found, use n tokens as the chunk size\n",
    "        if j == i + int(0.5 * n):\n",
    "            j = min(i + n, len(tokens))\n",
    "        yield tokens[i:j]\n",
    "        i = j\n",
    "\n",
    "\n",
    "def extract_chunk(content, template_prompt):\n",
    "    \"\"\"This function applies a prompt to some input content. In this case it returns a summarized chunk of text\"\"\"\n",
    "    prompt = template_prompt + content\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=GPT_MODEL, messages=[{\"role\": \"user\", \"content\": prompt}], temperature=0\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "def summarize_text(query):\n",
    "    \"\"\"This function does the following:\n",
    "    - Reads in the arxiv_library.csv file in including the embeddings\n",
    "    - Finds the closest file to the user's query\n",
    "    - Scrapes the text out of the file and chunks it\n",
    "    - Summarizes each chunk in parallel\n",
    "    - Does one final summary and returns this to the user\"\"\"\n",
    "\n",
    "    # A prompt to dictate how the recursive summarizations should approach the input paper\n",
    "    summary_prompt = \"\"\"Summarize this text from an academic paper. Extract any key points with reasoning.\\n\\nContent:\"\"\"\n",
    "\n",
    "    # If the library is empty (no searches have been performed yet), we perform one and download the results\n",
    "    library_df = pd.read_csv(paper_dir_filepath).reset_index()\n",
    "    if len(library_df) == 0:\n",
    "        print(\"No papers searched yet, downloading first.\")\n",
    "        get_articles(query)\n",
    "        print(\"Papers downloaded, continuing\")\n",
    "        library_df = pd.read_csv(paper_dir_filepath).reset_index()\n",
    "    library_df.columns = [\"title\", \"filepath\", \"embedding\"]\n",
    "    library_df[\"embedding\"] = library_df[\"embedding\"].apply(ast.literal_eval)\n",
    "    strings = strings_ranked_by_relatedness(query, library_df, top_n=2)\n",
    "    print(\"Chunking text from paper\")\n",
    "    pdf_text = read_pdf(strings[0])\n",
    "\n",
    "    # Initialise tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    results = \"\"\n",
    "\n",
    "    # Chunk up the document into 1500 token chunks\n",
    "    chunks = create_chunks(pdf_text, 1500, tokenizer)\n",
    "    text_chunks = [tokenizer.decode(chunk) for chunk in chunks]\n",
    "    print(\"Summarizing each chunk of text\")\n",
    "\n",
    "    # Parallel process the summaries\n",
    "    with concurrent.futures.ThreadPoolExecutor(\n",
    "        max_workers=len(text_chunks)\n",
    "    ) as executor:\n",
    "        futures = [\n",
    "            executor.submit(extract_chunk, chunk, summary_prompt)\n",
    "            for chunk in text_chunks\n",
    "        ]\n",
    "        with tqdm(total=len(text_chunks)) as pbar:\n",
    "            for _ in concurrent.futures.as_completed(futures):\n",
    "                pbar.update(1)\n",
    "        for future in futures:\n",
    "            data = future.result()\n",
    "            results += data\n",
    "\n",
    "    # Final summary\n",
    "    print(\"Summarizing into overall summary\")\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=GPT_MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Write a summary collated from this collection of key points extracted from an academic paper.\n",
    "                        The summary should highlight the core argument, conclusions and evidence, and answer the user's query.\n",
    "                        User query: {query}\n",
    "                        The summary should be structured in bulleted lists following the headings Core Argument, Evidence, and Conclusions.\n",
    "                        Key points:\\n{results}\\nSummary:\\n\"\"\",\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking text from paper\n",
      "Summarizing each chunk of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:36<00:00,  5.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing into overall summary\n"
     ]
    }
   ],
   "source": [
    "# Test the summarize_text function works\n",
    "chat_test_response = summarize_text(\"GPT working principles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core Argument:\n",
      "This academic paper explores the potential of using GPT-based agents in strategic game experiments, specifically the ultimatum game and the prisoner's dilemma game. The author develops prompts to enable GPT agents to understand and play the games. The results indicate that GPT can generate realistic outcomes and exhibit behavior consistent with human behavior in certain aspects. However, there are differences between GPT and human behavior, particularly in the evolution of choices over rounds.\n",
      "\n",
      "Evidence:\n",
      "- The author conducted experiments using GPT agents in the ultimatum and prisoner's dilemma games.\n",
      "- GPT agents exhibited behavior consistent with human behavior in certain aspects, but there were differences, especially in the evolution of choices over rounds.\n",
      "- The presence of social preference prompts had treatment effects on the behavior of GPT agents in both games.\n",
      "- GPT agents had difficulty with strategic reasoning and understanding the game structure without specific hints or guidelines in prompts.\n",
      "\n",
      "Conclusions:\n",
      "- GPT agents can generate realistic behaviors in simple strategic games and have the potential to complement traditional human experiments.\n",
      "- The performance of GPT is sensitive to input prompts, which can have advantages and disadvantages.\n",
      "- Future research should explore the strategic gameplay of artificial agents in more complex games using more advanced models.\n",
      "- Fine-tuning the language model or incorporating additional architectures may improve the performance of GPT agents in strategic game scenarios.\n"
     ]
    }
   ],
   "source": [
    "print(chat_test_response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
    "# def chat_completion_request(messages, functions=None, model=\"gpt-3.5-turbo-0613\"):\n",
    "#     headers = {\n",
    "#         \"Content-Type\": \"application/json\",\n",
    "#         \"Authorization\": \"Bearer \" + os.getenv(\"OPENAI_KEY\"),\n",
    "#     }\n",
    "#     json_data = {\"model\": model, \"messages\": messages}\n",
    "#     if functions is not None:\n",
    "#         json_data.update({\"functions\": functions})\n",
    "#     try:\n",
    "#         response = requests.post(\n",
    "#             \"https://api.openai.com/v1/chat/completions\",\n",
    "#             headers=headers,\n",
    "#             json=json_data,\n",
    "#         )\n",
    "#         return response\n",
    "#     except Exception as e:\n",
    "#         print(\"Unable to generate ChatCompletion response\")\n",
    "#         print(f\"Exception: {e}\")\n",
    "#         return e\n",
    "\n",
    "# @retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
    "# def chat_completion_request(messages, functions=None, model=GPT_MODEL):\n",
    "#     headers = {\n",
    "#         \"Content-Type\": \"application/json\",\n",
    "#         \"Authorization\": \"Bearer \" + os.getenv(\"OPENAI_KEY\"),\n",
    "#         # \"api-key\": openai.api_key,\n",
    "#     }\n",
    "#     json_data = {\"model\": model, \"messages\": messages}\n",
    "#     if functions is not None:\n",
    "#         json_data.update({\"functions\": functions})\n",
    "#     try:\n",
    "#         response = requests.post(\n",
    "#             \"https://api.openai.com/v1/chat/completions\",\n",
    "#             # \"https://gptvivi.openai.azure.com/openai/deployments/gpt-35-16k/chat/completions?api-version=2023-07-01-preview\",\n",
    "#             headers=headers,\n",
    "#             json=json_data,\n",
    "#         )\n",
    "#         return response\n",
    "#     except Exception as e:\n",
    "#         print(\"Unable to generate ChatCompletion response\")\n",
    "#         print(f\"Exception: {e}\")\n",
    "#         return e\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, functions=None, model=GPT_MODEL):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
    "    }\n",
    "    json_data = {\"model\": model, \"messages\": messages}\n",
    "    if functions is not None:\n",
    "        json_data.update({\"functions\": functions})\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "        engine=GPT_MODEL,\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conversation:\n",
    "    def __init__(self):\n",
    "        self.conversation_history = []\n",
    "\n",
    "    def add_message(self, role, content):\n",
    "        message = {\"role\": role, \"content\": content}\n",
    "        self.conversation_history.append(message)\n",
    "\n",
    "    def display_conversation(self, detailed=False):\n",
    "        role_to_color = {\n",
    "            \"system\": \"red\",\n",
    "            \"user\": \"green\",\n",
    "            \"assistant\": \"blue\",\n",
    "            \"function\": \"magenta\",\n",
    "        }\n",
    "        for message in self.conversation_history:\n",
    "            print(\n",
    "                colored(\n",
    "                    f\"{message['role']}: {message['content']}\\n\\n\",\n",
    "                    role_to_color[message[\"role\"]],\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate our get_articles and read_article_and_summarize functions\n",
    "arxiv_functions = [\n",
    "    {\n",
    "        \"name\": \"get_articles\",\n",
    "        \"description\": \"\"\"Use this function to get academic papers from arXiv to answer user questions.\"\"\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": f\"\"\"\n",
    "                            User query in JSON. Responses should be summarized and should include the article URL reference\n",
    "                            \"\"\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "        }\n",
    "    },{\n",
    "        \"name\": \"read_article_and_summarize\",\n",
    "        \"description\": \"\"\"Use this function to read whole papers and provide a summary for users.\n",
    "        You should NEVER call this function before get_articles has been called in the conversation.\"\"\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": f\"\"\"\n",
    "                            Description of the article in plain text based on the user's query\n",
    "                            \"\"\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "        },\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initiate our get_articles and read_article_and_summarize functions\n",
    "# arxiv_functions = [\n",
    "#     {\n",
    "#         \"name\": \"get_articles\",\n",
    "#         \"description\": \"\"\"Use this function to get academic papers from arXiv to answer user questions.\"\"\",\n",
    "#         \"parameters\": {\n",
    "#             \"type\": \"object\",\n",
    "#             \"properties\": {\n",
    "#                 \"query\": {\n",
    "#                     \"type\": \"string\",\n",
    "#                     \"description\": f\"\"\"\n",
    "#                             User query in JSON. Responses should be summarized and should include the article URL reference\n",
    "#                             \"\"\",\n",
    "#                 }\n",
    "#             },\n",
    "#             \"required\": [\"query\"],\n",
    "#         },\n",
    "#         \"name\": \"read_article_and_summarize\",\n",
    "#         \"description\": \"\"\"Use this function to read whole papers and provide a summary for users.\n",
    "#         You should NEVER call this function before get_articles has been called in the conversation.\"\"\",\n",
    "#         \"parameters\": {\n",
    "#             \"type\": \"object\",\n",
    "#             \"properties\": {\n",
    "#                 \"query\": {\n",
    "#                     \"type\": \"string\",\n",
    "#                     \"description\": f\"\"\"\n",
    "#                             Description of the article in plain text based on the user's query\n",
    "#                             \"\"\",\n",
    "#                 }\n",
    "#             },\n",
    "#             \"required\": [\"query\"],\n",
    "#         },\n",
    "#     }\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_completion_with_function_execution(messages, functions=[None]):\n",
    "    \"\"\"This function makes a ChatCompletion API call with the option of adding functions\"\"\"\n",
    "    response = chat_completion_request(messages, functions)\n",
    "    print(response.json())\n",
    "    full_message = response.json()[\"choices\"][0]\n",
    "    if full_message[\"finish_reason\"] == \"function_call\":\n",
    "        print(f\"Function generation requested, calling function\")\n",
    "        return call_arxiv_function(messages, full_message)\n",
    "    else:\n",
    "        print(f\"Function not required, responding to user\")\n",
    "        return response.json()\n",
    "\n",
    "def call_arxiv_function(messages, full_message):\n",
    "    \"\"\"Function calling function which executes function calls when the model believes it is necessary.\n",
    "    Currently extended by adding clauses to this if statement.\"\"\"\n",
    "\n",
    "    if full_message[\"message\"][\"function_call\"][\"name\"] == \"get_articles\":\n",
    "        try:\n",
    "            parsed_output = json.loads(\n",
    "                full_message[\"message\"][\"function_call\"][\"arguments\"]\n",
    "            )\n",
    "            print(\"Getting search results\")\n",
    "            results = get_articles(parsed_output[\"query\"])\n",
    "        except Exception as e:\n",
    "            print(parsed_output)\n",
    "            print(f\"Function execution failed\")\n",
    "            print(f\"Error message: {e}\")\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": full_message[\"message\"][\"function_call\"][\"name\"],\n",
    "                \"content\": str(results),\n",
    "            }\n",
    "        )\n",
    "        try:\n",
    "            print(\"Got search results, summarizing content\")\n",
    "            response = chat_completion_request(messages)\n",
    "            return response.json()\n",
    "        except Exception as e:\n",
    "            print(type(e))\n",
    "            raise Exception(\"Function chat request failed\")\n",
    "\n",
    "    elif (\n",
    "        full_message[\"message\"][\"function_call\"][\"name\"] == \"read_article_and_summarize\"\n",
    "    ):\n",
    "        parsed_output = json.loads(\n",
    "            full_message[\"message\"][\"function_call\"][\"arguments\"]\n",
    "        )\n",
    "        print(\"Finding and reading paper\")\n",
    "        summary = summarize_text(parsed_output[\"query\"])\n",
    "        return summary\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Function does not exist and cannot be called\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a system message\n",
    "paper_system_message = \"\"\"You are arXivGPT, a helpful assistant pulls academic papers to answer user questions.\n",
    "You summarize the papers clearly so the customer can decide which to read to answer their question.\n",
    "You always provide the article_url and title so the user can understand the name of the paper and click through to access it.\n",
    "Begin!\"\"\"\n",
    "paper_conversation = Conversation()\n",
    "paper_conversation.add_message(\"system\", paper_system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to generate ChatCompletion response\n",
      "Exception: Unrecognized request argument supplied: functions\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'InvalidRequestError' object has no attribute 'json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Add a user message\u001b[39;00m\n\u001b[1;32m      2\u001b[0m paper_conversation\u001b[39m.\u001b[39madd_message(\u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mHi, how does GPT and Transformer work?\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m chat_response \u001b[39m=\u001b[39m chat_completion_with_function_execution(\n\u001b[1;32m      4\u001b[0m     paper_conversation\u001b[39m.\u001b[39;49mconversation_history, functions\u001b[39m=\u001b[39;49marxiv_functions\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m assistant_message \u001b[39m=\u001b[39m chat_response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      7\u001b[0m paper_conversation\u001b[39m.\u001b[39madd_message(\u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, assistant_message)\n",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m, in \u001b[0;36mchat_completion_with_function_execution\u001b[0;34m(messages, functions)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"This function makes a ChatCompletion API call with the option of adding functions\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m response \u001b[39m=\u001b[39m chat_completion_request(messages, functions)\n\u001b[0;32m----> 4\u001b[0m full_message \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39;49mjson()[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[39mif\u001b[39;00m full_message[\u001b[39m\"\u001b[39m\u001b[39mfinish_reason\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfunction_call\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFunction generation requested, calling function\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'InvalidRequestError' object has no attribute 'json'"
     ]
    }
   ],
   "source": [
    "# Add a user message\n",
    "paper_conversation.add_message(\"user\", \"Hi, how does GPT and Transformer work?\")\n",
    "chat_response = chat_completion_with_function_execution(\n",
    "    paper_conversation.conversation_history, functions=arxiv_functions\n",
    ")\n",
    "assistant_message = chat_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "paper_conversation.add_message(\"assistant\", assistant_message)\n",
    "display(Markdown(assistant_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function generation requested, calling function\n",
      "Finding and reading paper\n",
      "Chunking text from paper\n",
      "Summarizing each chunk of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing into overall summary\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Core Argument:\n",
       "- This academic paper discusses the adaptation of language models (LMs) such as GPT, GPT-2, and BERT for automatic speech recognition (ASR).\n",
       "- The paper presents experimental results showing that fine-tuned GPT, GPT-2, and their combination outperform neural LMs trained from scratch on in-domain text.\n",
       "- The paper proposes a conversion method to compute the correct language prior probability based on bidirectional LM outputs, enabling BERT to achieve further improvements in ASR performance.\n",
       "- The paper highlights the limited number of studies on the use of GPT and BERT in ASR and provides a comprehensive review of the Transformer-based LM structures used in these models.\n",
       "\n",
       "Evidence:\n",
       "- Experimental results show that fine-tuned GPT, GPT-2, and their combination outperform neural LMs trained from scratch on in-domain text.\n",
       "- The paper presents a conversion method to compute the correct language prior probability based on bidirectional LM outputs, enabling BERT to achieve further improvements in ASR performance.\n",
       "- The paper provides results of word level LMs trained from scratch on the AMI corpus and evaluated on different datasets.\n",
       "- The experimental setup includes training data, acoustic models, and 100-best lists for rescoring.\n",
       "\n",
       "Conclusions:\n",
       "- Combining fine-tuned GPT, GPT-2, and BERT models achieves the lowest word error rates (WERs) in ASR.\n",
       "- Fine-tuning pre-trained LMs on in-domain datasets outperforms training LMs from scratch with only in-domain data.\n",
       "- The paper suggests that it may be more effective and efficient to fine-tune existing pre-trained LMs rather than building new LMs from scratch.\n",
       "- Optimization methods during inference should be considered for large pre-trained models.\n",
       "- The paper highlights the limited number of studies on the use of GPT and BERT in ASR and provides a comprehensive review of the Transformer-based LM structures used in these models."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add another user message to induce our system to use the second tool\n",
    "paper_conversation.add_message(\n",
    "    \"user\",\n",
    "    \"Can you read the Language Models for Speech Recognition paper for me and give me a summary\",\n",
    ")\n",
    "\n",
    "updated_response = chat_completion_with_function_execution(\n",
    "    paper_conversation.conversation_history, functions=arxiv_functions\n",
    ")\n",
    "display(Markdown(updated_response[\"choices\"][0][\"message\"][\"content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
